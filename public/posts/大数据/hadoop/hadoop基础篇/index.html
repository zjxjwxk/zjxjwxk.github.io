<!DOCTYPE html>
<html lang="en" dir="auto">

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="noindex, nofollow">
<title>Hadoop 基础篇 | Xinkang&#39;s Blog</title>
<meta name="keywords" content="Hadoop, 大数据">
<meta name="description" content="概要

大数据技术的相关概念
Hadoop 的架构和运行机制
实战：Hadoop 的安装和配置
实战：Hadoop 的开发

目标

掌握大数据存储与处理技术的原理（理论知识）
掌握 Hadoop 的使用和开发能力（实践能力）
结合书本，如《Hadoop 权威指南》

Hadoop 的前世今生
为了解决系统存在的瓶颈：存储容量、读写速率、计算效率&hellip; Google 提出了大数据技术：MapReduce、BigTable、GFS，这三样技术取得了革命性的变化：

成本降低，能用 PC 机，就不用大型机和高端存储
软件容错硬件故障视为常态，通过软件保证可靠性
简化并行分布式计算，无须控制节点同步和数据交换

但是，Google 只发表了相关的技术论文，没有开放源代码。于是，一个模仿 Google 大数据技术的开源实现出现了：Hadoop。
Hadoop 的功能和优势
Hadoop 是开源的分布式存储和分布式计算框架。
Hadoop 的组成
包含两个核心组件：

HDFS：分布式文件系统，存储海量的数据
MapReduce：并行处理框架，实现任务分解和调度

Hadoop 可以用来搭建大型数据仓库，PB 级数据的存储、处理、分析、统计等业务。如：搜索引擎、日志分析、商业智能、数据挖掘。
Hadoop 的优势

高扩展
低成本
成熟的生态圈（Hive、HBase 等）

Hadoop 生态系统及版本
Hadoop 生态系统


Hive：只需要编写 SQL 语句，Hive 就能够将其转化为一个 Hadoop 任务去执行，降低了使用 Hadoop 的门槛。


HBase：和传统的关系型数据库不同，HBase 放弃事务特性，追求更高的扩展；和 HDFS 不同，HBase 提供数据的随机读写和实时访问，实现对表数据的读写功能。


ZooKeeper：用于监控 Hadoop 集群的状态，管理一些配置，维护数据间节点的一致性等。


Hadoop 版本
ver1.x较为稳定且容易上手，本人将选择 ver1.x。">
<meta name="author" content="">
<link rel="canonical" href="http://localhost:1313/posts/%E5%A4%A7%E6%95%B0%E6%8D%AE/hadoop/hadoop%E5%9F%BA%E7%A1%80%E7%AF%87/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.d6fcd20a4fb86efa4dfac8ec95da60244cc8871042183da1ef28e3a762ad79c8.css" integrity="sha256-1vzSCk&#43;4bvpN&#43;sjsldpgJEzIhxBCGD2h7yjjp2Ktecg=" rel="preload stylesheet" as="style">
<link rel="icon" href="http://localhost:1313/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="http://localhost:1313/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://localhost:1313/favicon-32x32.png">
<link rel="apple-touch-icon" href="http://localhost:1313/apple-touch-icon.png">
<link rel="mask-icon" href="http://localhost:1313/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="http://localhost:1313/posts/%E5%A4%A7%E6%95%B0%E6%8D%AE/hadoop/hadoop%E5%9F%BA%E7%A1%80%E7%AF%87/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="http://localhost:1313/" accesskey="h" title="Xinkang&#39;s Blog (Alt + H)">Xinkang&#39;s Blog</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="http://localhost:1313/archives/" title="Archives">
                    <span>Archives</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/categories/" title="Categories">
                    <span>Categories</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/search/" title="Search (Alt &#43; /)" accesskey=/>
                    <span>Search</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      Hadoop 基础篇
    </h1>
    <div class="post-meta"><span title='2020-05-06 20:08:00 +0000 UTC'>May 6, 2020</span>

</div>
  </header> 
  <div class="post-content"><h1 id="概要">概要<a hidden class="anchor" aria-hidden="true" href="#概要">#</a></h1>
<ol>
<li>大数据技术的相关概念</li>
<li>Hadoop 的架构和运行机制</li>
<li>实战：Hadoop 的安装和配置</li>
<li>实战：Hadoop 的开发</li>
</ol>
<h1 id="目标">目标<a hidden class="anchor" aria-hidden="true" href="#目标">#</a></h1>
<ul>
<li>掌握大数据存储与处理技术的原理（理论知识）</li>
<li>掌握 Hadoop 的使用和开发能力（实践能力）</li>
<li>结合书本，如《Hadoop 权威指南》</li>
</ul>
<h1 id="hadoop-的前世今生">Hadoop 的前世今生<a hidden class="anchor" aria-hidden="true" href="#hadoop-的前世今生">#</a></h1>
<p>为了解决系统存在的瓶颈：存储容量、读写速率、计算效率&hellip; Google 提出了大数据技术：MapReduce、BigTable、GFS，这三样技术取得了革命性的变化：</p>
<ol>
<li>成本降低，能用 PC 机，就不用大型机和高端存储</li>
<li>软件容错硬件故障视为常态，通过软件保证可靠性</li>
<li>简化并行分布式计算，无须控制节点同步和数据交换</li>
</ol>
<p>但是，Google 只发表了相关的技术论文，没有开放源代码。于是，一个模仿 Google 大数据技术的开源实现出现了：Hadoop。</p>
<h1 id="hadoop-的功能和优势">Hadoop 的功能和优势<a hidden class="anchor" aria-hidden="true" href="#hadoop-的功能和优势">#</a></h1>
<p>Hadoop 是开源的分布式存储和分布式计算框架。</p>
<h2 id="hadoop-的组成">Hadoop 的组成<a hidden class="anchor" aria-hidden="true" href="#hadoop-的组成">#</a></h2>
<p>包含两个核心组件：</p>
<ol>
<li>HDFS：分布式文件系统，存储海量的数据</li>
<li>MapReduce：并行处理框架，实现任务分解和调度</li>
</ol>
<p>Hadoop 可以用来搭建大型数据仓库，PB 级数据的存储、处理、分析、统计等业务。如：搜索引擎、日志分析、商业智能、数据挖掘。</p>
<h2 id="hadoop-的优势">Hadoop 的优势<a hidden class="anchor" aria-hidden="true" href="#hadoop-的优势">#</a></h2>
<ol>
<li>高扩展</li>
<li>低成本</li>
<li>成熟的生态圈（Hive、HBase 等）</li>
</ol>
<h1 id="hadoop-生态系统及版本">Hadoop 生态系统及版本<a hidden class="anchor" aria-hidden="true" href="#hadoop-生态系统及版本">#</a></h1>
<h2 id="hadoop-生态系统">Hadoop 生态系统<a hidden class="anchor" aria-hidden="true" href="#hadoop-生态系统">#</a></h2>
<ul>
<li>
<p>Hive：只需要编写 SQL 语句，Hive 就能够将其转化为一个 Hadoop 任务去执行，降低了使用 Hadoop 的门槛。</p>
</li>
<li>
<p>HBase：和传统的关系型数据库不同，HBase 放弃事务特性，追求更高的扩展；和 HDFS 不同，HBase 提供数据的随机读写和实时访问，实现对表数据的读写功能。</p>
</li>
<li>
<p>ZooKeeper：用于监控 Hadoop 集群的状态，管理一些配置，维护数据间节点的一致性等。</p>
</li>
</ul>
<h2 id="hadoop-版本">Hadoop 版本<a hidden class="anchor" aria-hidden="true" href="#hadoop-版本">#</a></h2>
<p>ver1.x较为稳定且容易上手，本人将选择 ver1.x。</p>
<h1 id="安装-hadoop">安装 Hadoop<a hidden class="anchor" aria-hidden="true" href="#安装-hadoop">#</a></h1>
<ul>
<li>准备 Linux 环境</li>
<li>安装 JDK</li>
<li>配置 Hadoop</li>
</ul>
<h2 id="下载-hadoop">下载 Hadoop<a hidden class="anchor" aria-hidden="true" href="#下载-hadoop">#</a></h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>wget https://archive.apache.org/dist/hadoop/core/hadoop-1.2.1/hadoop-1.2.1.tar.gz
</span></span></code></pre></div><p>并解压之。</p>
<h2 id="配置-hadoop">配置 Hadoop<a hidden class="anchor" aria-hidden="true" href="#配置-hadoop">#</a></h2>
<p>在 conf 目录下找到 hadoop-env.sh 脚本，编辑之，将 JAVA_HOME 的注释去掉并配置为 Java 目录：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>export JAVA_HOME<span style="color:#f92672">=</span>/Library/Java/JavaVirtualMachines/jdk1.8.0_201.jdk/Contents/Home
</span></span></code></pre></div><p>配置 core.site.xml 添加如下配置：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-xml" data-lang="xml"><span style="display:flex;"><span><span style="color:#f92672">&lt;configuration&gt;</span>
</span></span><span style="display:flex;"><span>	<span style="color:#75715e">&lt;!-- Hadoop 的临时工作目录 --&gt;</span>
</span></span><span style="display:flex;"><span>	<span style="color:#f92672">&lt;property&gt;</span>
</span></span><span style="display:flex;"><span>		<span style="color:#f92672">&lt;name&gt;</span>hadoop.tmp.dir<span style="color:#f92672">&lt;/name&gt;</span>
</span></span><span style="display:flex;"><span>		<span style="color:#f92672">&lt;value&gt;</span>/hadoop<span style="color:#f92672">&lt;/value&gt;</span>
</span></span><span style="display:flex;"><span>	<span style="color:#f92672">&lt;/property&gt;</span>
</span></span><span style="display:flex;"><span>	<span style="color:#75715e">&lt;!-- Hadoop 的元数据目录 --&gt;</span>
</span></span><span style="display:flex;"><span>	<span style="color:#f92672">&lt;property&gt;</span>
</span></span><span style="display:flex;"><span>		<span style="color:#f92672">&lt;name&gt;</span>dfs.name.dir<span style="color:#f92672">&lt;/name&gt;</span>
</span></span><span style="display:flex;"><span>		<span style="color:#f92672">&lt;value&gt;</span>/hadoop/name<span style="color:#f92672">&lt;/value&gt;</span>
</span></span><span style="display:flex;"><span>	<span style="color:#f92672">&lt;/property&gt;</span>
</span></span><span style="display:flex;"><span>	<span style="color:#75715e">&lt;!-- 文件系统 namenode 的访问地址 --&gt;</span>
</span></span><span style="display:flex;"><span>	<span style="color:#f92672">&lt;property&gt;</span>
</span></span><span style="display:flex;"><span>		<span style="color:#f92672">&lt;name&gt;</span>fs.default.name<span style="color:#f92672">&lt;/name&gt;</span>
</span></span><span style="display:flex;"><span>		<span style="color:#f92672">&lt;value&gt;</span>hdfs://localhost:9000<span style="color:#f92672">&lt;/value&gt;</span>
</span></span><span style="display:flex;"><span>	<span style="color:#f92672">&lt;/property&gt;</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">&lt;/configuration&gt;</span>
</span></span></code></pre></div><p>配置 hdfs-site.xml：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-xml" data-lang="xml"><span style="display:flex;"><span><span style="color:#f92672">&lt;configuration&gt;</span>
</span></span><span style="display:flex;"><span>	<span style="color:#75715e">&lt;!-- dfs 文件块的存放目录，文件系统的数据目录 --&gt;</span>
</span></span><span style="display:flex;"><span>	<span style="color:#f92672">&lt;property&gt;</span>
</span></span><span style="display:flex;"><span>		<span style="color:#f92672">&lt;name&gt;</span>dfs.data.dir<span style="color:#f92672">&lt;/name&gt;</span>
</span></span><span style="display:flex;"><span>		<span style="color:#f92672">&lt;value&gt;</span>/hadoop/data<span style="color:#f92672">&lt;/value&gt;</span>
</span></span><span style="display:flex;"><span>	<span style="color:#f92672">&lt;/property&gt;</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">&lt;/configuration&gt;</span>
</span></span></code></pre></div><p>配置 mapred-site.xml</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-xml" data-lang="xml"><span style="display:flex;"><span><span style="color:#f92672">&lt;configuration&gt;</span>
</span></span><span style="display:flex;"><span>	<span style="color:#75715e">&lt;!-- MapReduce 的 job tracker 访问地址 --&gt;</span>
</span></span><span style="display:flex;"><span>	<span style="color:#f92672">&lt;property&gt;</span>
</span></span><span style="display:flex;"><span>		<span style="color:#f92672">&lt;name&gt;</span>mapred.job.tracker<span style="color:#f92672">&lt;/name&gt;</span>
</span></span><span style="display:flex;"><span>		<span style="color:#f92672">&lt;value&gt;</span>localhost:9001<span style="color:#f92672">&lt;/value&gt;</span>
</span></span><span style="display:flex;"><span>	<span style="color:#f92672">&lt;/property&gt;</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">&lt;/configuration&gt;</span>
</span></span></code></pre></div><p>配置 Hadoop 环境变量，编辑 /etc/profile，添加以下：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>export HADOOP_HOME<span style="color:#f92672">=</span>/Library/hadoop-1.2.1
</span></span><span style="display:flex;"><span>export PATH<span style="color:#f92672">=</span>$PATH:$HADOOP_HOME/bin
</span></span></code></pre></div><h2 id="启动-hadoop">启动 Hadoop<a hidden class="anchor" aria-hidden="true" href="#启动-hadoop">#</a></h2>
<p>对 NameNode 进行格式化操作：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>hadoop namenode -format
</span></span></code></pre></div><p>启动 Hadoop，执行 bin/start-all.sh ，使用 jps 命令查看是否有以下进程，若有则表示 Hadoop 已正常运行：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#ae81ff">10690</span> NameNode
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">10773</span> DataNode
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">10920</span> JobTracker
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">10859</span> SecondaryNameNode
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">11003</span> TaskTracker
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">11101</span> Jps
</span></span></code></pre></div><p>可以查看 Hadoop 下有哪些文件：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>hadoop fs -ls /
</span></span></code></pre></div><h1 id="hadoop-的核心hdfs简介">Hadoop 的核心——HDFS简介<a hidden class="anchor" aria-hidden="true" href="#hadoop-的核心hdfs简介">#</a></h1>
<h2 id="hdfs-设计架构">HDFS 设计架构<a hidden class="anchor" aria-hidden="true" href="#hdfs-设计架构">#</a></h2>
<ul>
<li>块（Block）</li>
<li>NameNode</li>
<li>DataNode</li>
</ul>
<h3 id="块block">块（Block）<a hidden class="anchor" aria-hidden="true" href="#块block">#</a></h3>
<p>HDFS 的文件被分成块进行存储，块的默认大小为 64MB，块是文件存储处理的逻辑单元。</p>
<h3 id="节点node">节点（Node）<a hidden class="anchor" aria-hidden="true" href="#节点node">#</a></h3>
<p>HDFS 中有两类节点 NameNode 和 DataNode：</p>
<h4 id="namenode">NameNode<a hidden class="anchor" aria-hidden="true" href="#namenode">#</a></h4>
<p>NameNode 是管理节点，存放文件元数据：</p>
<ol>
<li>文件与数据块的映射表</li>
<li>数据块与数据节点的映射表</li>
</ol>
<h4 id="datanode">DataNode<a hidden class="anchor" aria-hidden="true" href="#datanode">#</a></h4>
<p>DateNode 是 HDFS 的工作节点，存放数据块：</p>
<p><img alt="HDFS 设计架构" loading="lazy" src="/posts/%E5%A4%A7%E6%95%B0%E6%8D%AE/hadoop/hadoop%E5%9F%BA%E7%A1%80%E7%AF%87/images/image-20200507142142615.png"></p>
<h2 id="数据管理策略">数据管理策略<a hidden class="anchor" aria-hidden="true" href="#数据管理策略">#</a></h2>
<h3 id="冗余数据块">冗余数据块<a hidden class="anchor" aria-hidden="true" href="#冗余数据块">#</a></h3>
<p>每个数据块 3 个副本，分布在两个机架内的三个节点，存储冗余数据是为了预防数据丢失。</p>
<p><img alt="数据管理策略" loading="lazy" src="/posts/%E5%A4%A7%E6%95%B0%E6%8D%AE/hadoop/hadoop%E5%9F%BA%E7%A1%80%E7%AF%87/images/image-20200507142935890.png"></p>
<h3 id="心跳检测">心跳检测<a hidden class="anchor" aria-hidden="true" href="#心跳检测">#</a></h3>
<p>每隔一段时间，DataNode 就像 NameNode 发送自己的状态：</p>
<p><img alt="心跳检测" loading="lazy" src="/posts/%E5%A4%A7%E6%95%B0%E6%8D%AE/hadoop/hadoop%E5%9F%BA%E7%A1%80%E7%AF%87/images/image-20200507143153831.png"></p>
<h3 id="二级-namenode">二级 NameNode<a hidden class="anchor" aria-hidden="true" href="#二级-namenode">#</a></h3>
<p>二级 NameNode 定期同步元数据映像文件和修改日志，NameNode 发生故障时，备胎转正，以保证 NameNode 的高可用性。</p>
<p><img alt="Secondary NameNode" loading="lazy" src="/posts/%E5%A4%A7%E6%95%B0%E6%8D%AE/hadoop/hadoop%E5%9F%BA%E7%A1%80%E7%AF%87/images/image-20200507143448919.png"></p>
<h2 id="hdfs-中文件的读写操作">HDFS 中文件的读写操作<a hidden class="anchor" aria-hidden="true" href="#hdfs-中文件的读写操作">#</a></h2>
<h3 id="hdfs-读取文件的流程">HDFS 读取文件的流程<a hidden class="anchor" aria-hidden="true" href="#hdfs-读取文件的流程">#</a></h3>
<ol>
<li>客户端（Java 程序或命令行）向 NameNode 发起文件读取请求，把文件名和路径告诉 NameNode</li>
<li>NameNode 查询元数据，并返回给客户端，客户端就知道了这个文件包含哪些块，以及这些块分别能在哪些 DataNode 里找到</li>
<li>然后，客户端就能从这些 DataNode 找到这些块，并读取下载，再对它们进行组装</li>
</ol>
<p><img alt="HDFS读取文件" loading="lazy" src="/posts/%E5%A4%A7%E6%95%B0%E6%8D%AE/hadoop/hadoop%E5%9F%BA%E7%A1%80%E7%AF%87/images/image-20200507144702645.png"></p>
<h3 id="hdfs-写入文件的流程">HDFS 写入文件的流程<a hidden class="anchor" aria-hidden="true" href="#hdfs-写入文件的流程">#</a></h3>
<ol>
<li>客户端将需要写的文件拆分成块，并通知 NameNode</li>
<li>NameNode 会找到当前可用的磁盘空间中的 DataNodes，并返回给客户端</li>
<li>根据返回的 DataNodes，客户端将这些块写入 DataNodes</li>
<li>客户端在向 DataNode 写入一个块后，DataNode 就要通过管道进行流水线复制</li>
<li>复制完之后，就对 NameNode 更新元数据</li>
</ol>
<p><img alt="HDFS写入文件" loading="lazy" src="/posts/%E5%A4%A7%E6%95%B0%E6%8D%AE/hadoop/hadoop%E5%9F%BA%E7%A1%80%E7%AF%87/images/image-20200507145230830.png"></p>
<h2 id="hdfs-的特点">HDFS 的特点<a hidden class="anchor" aria-hidden="true" href="#hdfs-的特点">#</a></h2>
<h3 id="特点">特点<a hidden class="anchor" aria-hidden="true" href="#特点">#</a></h3>
<ul>
<li>数据冗余，硬件容错</li>
<li>流式的数据访问（写一次，读多次）</li>
<li>存储大文件</li>
</ul>
<h3 id="适用性和局限性">适用性和局限性<a hidden class="anchor" aria-hidden="true" href="#适用性和局限性">#</a></h3>
<ul>
<li>适合数据批量读写，吞度量高（但不适合交互式应用，低延迟很难满足）</li>
<li>适合一次写入多次读取，顺序读写（但不支持多用户并发写相同文件）</li>
</ul>
<h2 id="hdfs-的使用">HDFS 的使用<a hidden class="anchor" aria-hidden="true" href="#hdfs-的使用">#</a></h2>
<h3 id="格式化-namenode">格式化 NameNode<a hidden class="anchor" aria-hidden="true" href="#格式化-namenode">#</a></h3>
<p>先对 NameNode 进行格式化操作：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>hadoop namenode -format
</span></span></code></pre></div><h3 id="创建文件夹">创建文件夹<a hidden class="anchor" aria-hidden="true" href="#创建文件夹">#</a></h3>
<p>在 HDFS 中创建一个文件夹 input：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>hadoop fs -mkdir input
</span></span></code></pre></div><p>input 文件夹将会在 HDFS 中的 /user/root/ 下</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>MacBook-Pro-of-Wxk:~ root# hadoop fs -ls /user/root/input
</span></span><span style="display:flex;"><span>Found <span style="color:#ae81ff">1</span> items
</span></span><span style="display:flex;"><span>-rw-r--r--   <span style="color:#ae81ff">3</span> root supergroup          <span style="color:#ae81ff">0</span> 2020-05-07 15:26 /user/root/input
</span></span></code></pre></div><h3 id="上传文件">上传文件<a hidden class="anchor" aria-hidden="true" href="#上传文件">#</a></h3>
<p>将本地 test.txt 文件上传到 HDFS 中刚刚创建的 input 中：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>hadoop fs -put test.txt input/
</span></span></code></pre></div><p>这样就能在 /user/root/input/ 下找到该文件了</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>MacBook-Pro-of-Wxk:~ root# hadoop fs -ls /user/root/input
</span></span><span style="display:flex;"><span>Found <span style="color:#ae81ff">1</span> items
</span></span><span style="display:flex;"><span>-rw-r--r--   <span style="color:#ae81ff">3</span> root supergroup         <span style="color:#ae81ff">14</span> 2020-05-07 16:00 /user/root/input/test.txt
</span></span></code></pre></div><h4 id="读取文件">读取文件<a hidden class="anchor" aria-hidden="true" href="#读取文件">#</a></h4>
<p>输出 HDFS 中的文件：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>MacBook-Pro-of-Wxk:~ root# hadoop fs -cat input/test.txt
</span></span><span style="display:flex;"><span>Hello Hadoop!
</span></span></code></pre></div><h4 id="下载文件">下载文件<a hidden class="anchor" aria-hidden="true" href="#下载文件">#</a></h4>
<p>从 HDFS 下载指定路径下的文件到本地：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>hadoop fs -get input/test.txt test2.txt
</span></span></code></pre></div><p>即可在本地找到该文件：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>MacBook-Pro-of-Wxk:~ root# cat test2.txt 
</span></span><span style="display:flex;"><span>Hello Hadoop!
</span></span></code></pre></div><h4 id="查看-namenode-信息">查看 NameNode 信息<a hidden class="anchor" aria-hidden="true" href="#查看-namenode-信息">#</a></h4>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>MacBook-Pro-of-Wxk:~ root# hadoop dfsadmin -report
</span></span><span style="display:flex;"><span>Configured Capacity: <span style="color:#ae81ff">249531727872</span> <span style="color:#f92672">(</span>232.39 GB<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>Present Capacity: <span style="color:#ae81ff">83015577640</span> <span style="color:#f92672">(</span>77.31 GB<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>DFS Remaining: <span style="color:#ae81ff">83015569408</span> <span style="color:#f92672">(</span>77.31 GB<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>DFS Used: <span style="color:#ae81ff">8232</span> <span style="color:#f92672">(</span>8.04 KB<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>DFS Used%: 0%
</span></span><span style="display:flex;"><span>Under replicated blocks: <span style="color:#ae81ff">2</span>
</span></span><span style="display:flex;"><span>Blocks with corrupt replicas: <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>Missing blocks: <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>-------------------------------------------------
</span></span><span style="display:flex;"><span>Datanodes available: <span style="color:#ae81ff">1</span> <span style="color:#f92672">(</span><span style="color:#ae81ff">1</span> total, <span style="color:#ae81ff">0</span> dead<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Name: 127.0.0.1:50010
</span></span><span style="display:flex;"><span>Decommission Status : Normal
</span></span><span style="display:flex;"><span>Configured Capacity: <span style="color:#ae81ff">249531727872</span> <span style="color:#f92672">(</span>232.39 GB<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>DFS Used: <span style="color:#ae81ff">8232</span> <span style="color:#f92672">(</span>8.04 KB<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>Non DFS Used: <span style="color:#ae81ff">166516150232</span> <span style="color:#f92672">(</span>155.08 GB<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>DFS Remaining: 83015569408<span style="color:#f92672">(</span>77.31 GB<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>DFS Used%: 0%
</span></span><span style="display:flex;"><span>DFS Remaining%: 33.27%
</span></span><span style="display:flex;"><span>Last contact: Thu May <span style="color:#ae81ff">07</span> 16:09:02 CST <span style="color:#ae81ff">2020</span>
</span></span></code></pre></div><h1 id="hadoop-的核心mapreduce-原理与实现">Hadoop 的核心——MapReduce 原理与实现<a hidden class="anchor" aria-hidden="true" href="#hadoop-的核心mapreduce-原理与实现">#</a></h1>
<h2 id="mapreduce-原理">MapReduce 原理<a hidden class="anchor" aria-hidden="true" href="#mapreduce-原理">#</a></h2>
<p>分而治之，一个大任务分成多个小的子任务（map），并行执行后，合并结果（reduce）。</p>
<p>假如有 100 副扑克牌混在了一起，其中少了一张，怎么找出缺少的那一张？</p>
<ul>
<li>Map：随机分为 100 副扑克牌，各自统计该副牌总每张牌的出现次数。</li>
<li>Reduce：通过交换每副牌各自统计的结果，再次统计总的每张牌出现次数。一个 Reduce 统计一张牌的总出现次数。</li>
</ul>
<p>最后对每张牌的总出现次数进行排序，筛选出结果。</p>
<p><img alt="MapReduce过程" loading="lazy" src="/posts/%E5%A4%A7%E6%95%B0%E6%8D%AE/hadoop/hadoop%E5%9F%BA%E7%A1%80%E7%AF%87/images/image-20200507162434845.png"></p>
<p>再如：100 GB 的网站访问日志文件，找出访问次数最多的 IP 地址；SELECT 表查询操作、JOIN 表连接操作，都可以通过 MapReduce 来实现。</p>
<h2 id="mapreduce-的运行流程">MapReduce 的运行流程<a hidden class="anchor" aria-hidden="true" href="#mapreduce-的运行流程">#</a></h2>
<ul>
<li>Job &amp; Task</li>
<li>JobTracker</li>
<li>TaskTracker</li>
</ul>
<h3 id="job--task">Job &amp; Task<a hidden class="anchor" aria-hidden="true" href="#job--task">#</a></h3>
<p>一个 Job 拆分为多个 Task 来解决，Task 又分为 MapTask 和 ReduceTask。</p>
<p><img alt="JobTracker和TaskTracker" loading="lazy" src="/posts/%E5%A4%A7%E6%95%B0%E6%8D%AE/hadoop/hadoop%E5%9F%BA%E7%A1%80%E7%AF%87/images/image-20200507163935796.png"></p>
<h3 id="jobtracker">JobTracker<a hidden class="anchor" aria-hidden="true" href="#jobtracker">#</a></h3>
<ul>
<li>作业调度</li>
<li>分配任务、监控任务执行进度</li>
<li>监控 TaskTracker 的状态</li>
</ul>
<h3 id="tasktracker">TaskTracker<a hidden class="anchor" aria-hidden="true" href="#tasktracker">#</a></h3>
<ul>
<li>执行任务</li>
<li>汇报任务状态</li>
</ul>
<p><img alt="MapReduce作业执行过程" loading="lazy" src="/posts/%E5%A4%A7%E6%95%B0%E6%8D%AE/hadoop/hadoop%E5%9F%BA%E7%A1%80%E7%AF%87/images/image-20200508095635229.png"></p>
<h2 id="mapreduce-的容错机制">MapReduce 的容错机制<a hidden class="anchor" aria-hidden="true" href="#mapreduce-的容错机制">#</a></h2>
<h3 id="重复执行">重复执行<a hidden class="anchor" aria-hidden="true" href="#重复执行">#</a></h3>
<p>重复执行将会最多重复执行四次任务，若仍然失败则放弃执行。</p>
<h3 id="推测执行">推测执行<a hidden class="anchor" aria-hidden="true" href="#推测执行">#</a></h3>
<p>当 JobTracker 发现其中某个 TaskTracker 执行特别慢的时候，就会另开一个 TaskTracker 执行该任务，这两个 Task 谁先执行完，则终止另一个。</p>
<p><img alt="推测执行" loading="lazy" src="/posts/%E5%A4%A7%E6%95%B0%E6%8D%AE/hadoop/hadoop%E5%9F%BA%E7%A1%80%E7%AF%87/images/image-20200508095746307.png"></p>
<h1 id="开发-hadoop-应用程序">开发 Hadoop 应用程序<a hidden class="anchor" aria-hidden="true" href="#开发-hadoop-应用程序">#</a></h1>
<h2 id="wordcount-单词计数">WordCount 单词计数<a hidden class="anchor" aria-hidden="true" href="#wordcount-单词计数">#</a></h2>
<p>WordCount 单次计数：计算文件中出现每个单词的频数，输出结果按照字母顺序进行排序。</p>
<h3 id="mapreduce-过程">MapReduce 过程<a hidden class="anchor" aria-hidden="true" href="#mapreduce-过程">#</a></h3>
<p><img alt="Map过程" loading="lazy" src="/posts/%E5%A4%A7%E6%95%B0%E6%8D%AE/hadoop/hadoop%E5%9F%BA%E7%A1%80%E7%AF%87/images/image-20200508100649309.png"></p>
<p><img alt="Reduce过程" loading="lazy" src="/posts/%E5%A4%A7%E6%95%B0%E6%8D%AE/hadoop/hadoop%E5%9F%BA%E7%A1%80%E7%AF%87/images/image-20200508100706460.png"></p>
<h3 id="源码">源码<a hidden class="anchor" aria-hidden="true" href="#源码">#</a></h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-java" data-lang="java"><span style="display:flex;"><span><span style="color:#f92672">package</span> com.zjut;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> java.io.IOException;
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> java.util.StringTokenizer;
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> org.apache.hadoop.conf.Configuration;
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> org.apache.hadoop.fs.Path;
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> org.apache.hadoop.io.IntWritable;
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> org.apache.hadoop.io.LongWritable;
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> org.apache.hadoop.io.Text;
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> org.apache.hadoop.mapreduce.Job;
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> org.apache.hadoop.mapreduce.Mapper;
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> org.apache.hadoop.mapreduce.Reducer;
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> org.apache.hadoop.mapreduce.lib.input.TextInputFormat;
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> org.apache.hadoop.mapreduce.lib.output.TextOutputFormat;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">/**
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"> * @author zjxjwxk
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"> */</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">public</span> <span style="color:#66d9ef">class</span> <span style="color:#a6e22e">WordCount</span> {
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">public</span> <span style="color:#66d9ef">static</span> <span style="color:#66d9ef">class</span> <span style="color:#a6e22e">WordCountMap</span> <span style="color:#66d9ef">extends</span>
</span></span><span style="display:flex;"><span>            Mapper<span style="color:#f92672">&lt;</span>LongWritable, Text, Text, IntWritable<span style="color:#f92672">&gt;</span> {
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">private</span> <span style="color:#66d9ef">final</span> IntWritable one <span style="color:#f92672">=</span> <span style="color:#66d9ef">new</span> IntWritable(1);
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">private</span> Text word <span style="color:#f92672">=</span> <span style="color:#66d9ef">new</span> Text();
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#a6e22e">@Override</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">public</span> <span style="color:#66d9ef">void</span> <span style="color:#a6e22e">map</span>(LongWritable key, Text value, Context context)
</span></span><span style="display:flex;"><span>                <span style="color:#66d9ef">throws</span> IOException, InterruptedException {
</span></span><span style="display:flex;"><span>            String line <span style="color:#f92672">=</span> value.<span style="color:#a6e22e">toString</span>();
</span></span><span style="display:flex;"><span>            StringTokenizer token <span style="color:#f92672">=</span> <span style="color:#66d9ef">new</span> StringTokenizer(line);
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">while</span> (token.<span style="color:#a6e22e">hasMoreTokens</span>()) {
</span></span><span style="display:flex;"><span>                word.<span style="color:#a6e22e">set</span>(token.<span style="color:#a6e22e">nextToken</span>());
</span></span><span style="display:flex;"><span>                context.<span style="color:#a6e22e">write</span>(word, one);
</span></span><span style="display:flex;"><span>            }
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">public</span> <span style="color:#66d9ef">static</span> <span style="color:#66d9ef">class</span> <span style="color:#a6e22e">WordCountReduce</span> <span style="color:#66d9ef">extends</span>
</span></span><span style="display:flex;"><span>            Reducer<span style="color:#f92672">&lt;</span>Text, IntWritable, Text, IntWritable<span style="color:#f92672">&gt;</span> {
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#a6e22e">@Override</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">public</span> <span style="color:#66d9ef">void</span> <span style="color:#a6e22e">reduce</span>(Text key, Iterable<span style="color:#f92672">&lt;</span>IntWritable<span style="color:#f92672">&gt;</span> values,
</span></span><span style="display:flex;"><span>                           Context context) <span style="color:#66d9ef">throws</span> IOException, InterruptedException {
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">int</span> sum <span style="color:#f92672">=</span> 0;
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">for</span> (IntWritable val : values) {
</span></span><span style="display:flex;"><span>                sum <span style="color:#f92672">+=</span> val.<span style="color:#a6e22e">get</span>();
</span></span><span style="display:flex;"><span>            }
</span></span><span style="display:flex;"><span>            context.<span style="color:#a6e22e">write</span>(key, <span style="color:#66d9ef">new</span> IntWritable(sum));
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">public</span> <span style="color:#66d9ef">static</span> <span style="color:#66d9ef">void</span> <span style="color:#a6e22e">main</span>(String<span style="color:#f92672">[]</span> args) <span style="color:#66d9ef">throws</span> Exception {
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        Configuration conf <span style="color:#f92672">=</span> <span style="color:#66d9ef">new</span> Configuration();
</span></span><span style="display:flex;"><span>        Job job <span style="color:#f92672">=</span> <span style="color:#66d9ef">new</span> Job(conf);
</span></span><span style="display:flex;"><span>        job.<span style="color:#a6e22e">setJarByClass</span>(WordCount.<span style="color:#a6e22e">class</span>);
</span></span><span style="display:flex;"><span>        job.<span style="color:#a6e22e">setJobName</span>(<span style="color:#e6db74">&#34;wordcount&#34;</span>);
</span></span><span style="display:flex;"><span>        job.<span style="color:#a6e22e">setOutputKeyClass</span>(Text.<span style="color:#a6e22e">class</span>);
</span></span><span style="display:flex;"><span>        job.<span style="color:#a6e22e">setOutputValueClass</span>(IntWritable.<span style="color:#a6e22e">class</span>);
</span></span><span style="display:flex;"><span>        job.<span style="color:#a6e22e">setMapperClass</span>(WordCountMap.<span style="color:#a6e22e">class</span>);
</span></span><span style="display:flex;"><span>        job.<span style="color:#a6e22e">setReducerClass</span>(WordCountReduce.<span style="color:#a6e22e">class</span>);
</span></span><span style="display:flex;"><span>        job.<span style="color:#a6e22e">setInputFormatClass</span>(TextInputFormat.<span style="color:#a6e22e">class</span>);
</span></span><span style="display:flex;"><span>        job.<span style="color:#a6e22e">setOutputFormatClass</span>(TextOutputFormat.<span style="color:#a6e22e">class</span>);
</span></span><span style="display:flex;"><span>        FileInputFormat.<span style="color:#a6e22e">addInputPath</span>(job, <span style="color:#66d9ef">new</span> Path(args<span style="color:#f92672">[</span>0<span style="color:#f92672">]</span>));
</span></span><span style="display:flex;"><span>        FileOutputFormat.<span style="color:#a6e22e">setOutputPath</span>(job, <span style="color:#66d9ef">new</span> Path(args<span style="color:#f92672">[</span>1<span style="color:#f92672">]</span>));
</span></span><span style="display:flex;"><span>        job.<span style="color:#a6e22e">waitForCompletion</span>(<span style="color:#66d9ef">true</span>);
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><h3 id="编译和打包">编译和打包<a hidden class="anchor" aria-hidden="true" href="#编译和打包">#</a></h3>
<p>编译（添加 classpath 依赖包）：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>javac -classpath /Library/hadoop-1.2.1/hadoop-core-1.2.1.jar:/Library/hadoop-1.2.1/lib/commons-cli-1.2.jar -d WordCountClass/ WordCount.java
</span></span></code></pre></div><p>打包所有 class 文件为 jar 包：</p>
<pre tabindex="0"><code>jar -cvf WordCount.jar *.class
</code></pre><h3 id="准备文件">准备文件<a hidden class="anchor" aria-hidden="true" href="#准备文件">#</a></h3>
<p>创建一个 input 文件夹，在里面添加两个文本文件：</p>
<p>Hello.txt</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-txt" data-lang="txt"><span style="display:flex;"><span>Hello World
</span></span><span style="display:flex;"><span>Hello Hadoop
</span></span><span style="display:flex;"><span>Hello HDFS
</span></span><span style="display:flex;"><span>Hello Map
</span></span><span style="display:flex;"><span>Hello Reduce
</span></span></code></pre></div><p>Hello2.txt</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-txt" data-lang="txt"><span style="display:flex;"><span>Hadoop World
</span></span><span style="display:flex;"><span>Hadoop NameNode
</span></span><span style="display:flex;"><span>Hadoop DataNode
</span></span><span style="display:flex;"><span>Hadoop MapReduce
</span></span><span style="display:flex;"><span>Hello BigData
</span></span></code></pre></div><h3 id="上传文件-1">上传文件<a hidden class="anchor" aria-hidden="true" href="#上传文件-1">#</a></h3>
<p>在 HDFS 中创建一个 input_wordcount 文件夹：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>hadoop fs -mkdir input_wordcount
</span></span></code></pre></div><p>将两个文本文件上传到 HDFS：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>hadoop fs -put input/* input_wordcount/
</span></span></code></pre></div><p>可以在 HDFS 中找到这两个文件：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>MacBook-Pro-of-Wxk:Project root# hadoop fs -ls input_wordcount
</span></span><span style="display:flex;"><span>Found <span style="color:#ae81ff">2</span> items
</span></span><span style="display:flex;"><span>-rw-r--r--   <span style="color:#ae81ff">3</span> root supergroup         <span style="color:#ae81ff">59</span> 2020-05-08 13:51 /user/root/input_wordcount/Hello.txt
</span></span><span style="display:flex;"><span>-rw-r--r--   <span style="color:#ae81ff">3</span> root supergroup         <span style="color:#ae81ff">76</span> 2020-05-08 13:51 /user/root/input_wordcount/Hello2.txt
</span></span></code></pre></div><h3 id="执行-mapreduce">执行 MapReduce<a hidden class="anchor" aria-hidden="true" href="#执行-mapreduce">#</a></h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>hadoop jar Hadoop/WordCount/WordCountClass/WordCount.jar WordCount input_wordcount output_wordcount
</span></span></code></pre></div><p>hadoop 中执行本地 jar 包，最后有两个参数 <code>input_wordcount</code>,  <code>output_wordcount</code>，分别为输入路径和输出路径。</p>
<p>执行过程和结果：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>20/05/08 13:59:11 WARN mapred.JobClient: Use GenericOptionsParser <span style="color:#66d9ef">for</span> parsing the arguments. Applications should implement Tool <span style="color:#66d9ef">for</span> the same.
</span></span><span style="display:flex;"><span>20/05/08 13:59:11 INFO input.FileInputFormat: Total input paths to process : <span style="color:#ae81ff">2</span>
</span></span><span style="display:flex;"><span>20/05/08 13:59:11 WARN util.NativeCodeLoader: Unable to load native-hadoop library <span style="color:#66d9ef">for</span> your platform... using builtin-java classes where applicable
</span></span><span style="display:flex;"><span>20/05/08 13:59:11 WARN snappy.LoadSnappy: Snappy native library not loaded
</span></span><span style="display:flex;"><span>20/05/08 13:59:11 INFO mapred.JobClient: Running job: job_202005081303_0001
</span></span><span style="display:flex;"><span>20/05/08 13:59:12 INFO mapred.JobClient:  map 0% reduce 0%
</span></span><span style="display:flex;"><span>20/05/08 13:59:15 INFO mapred.JobClient:  map 100% reduce 0%
</span></span><span style="display:flex;"><span>20/05/08 13:59:22 INFO mapred.JobClient:  map 100% reduce 33%
</span></span><span style="display:flex;"><span>20/05/08 13:59:23 INFO mapred.JobClient:  map 100% reduce 100%
</span></span><span style="display:flex;"><span>20/05/08 13:59:24 INFO mapred.JobClient: Job complete: job_202005081303_0001
</span></span><span style="display:flex;"><span>20/05/08 13:59:24 INFO mapred.JobClient: Counters: <span style="color:#ae81ff">26</span>
</span></span><span style="display:flex;"><span>20/05/08 13:59:24 INFO mapred.JobClient:   Map-Reduce Framework
</span></span><span style="display:flex;"><span>20/05/08 13:59:24 INFO mapred.JobClient:     Spilled Records<span style="color:#f92672">=</span><span style="color:#ae81ff">40</span>
</span></span><span style="display:flex;"><span>20/05/08 13:59:24 INFO mapred.JobClient:     Map output materialized bytes<span style="color:#f92672">=</span><span style="color:#ae81ff">267</span>
</span></span><span style="display:flex;"><span>20/05/08 13:59:24 INFO mapred.JobClient:     Reduce input records<span style="color:#f92672">=</span><span style="color:#ae81ff">20</span>
</span></span><span style="display:flex;"><span>20/05/08 13:59:24 INFO mapred.JobClient:     Map input records<span style="color:#f92672">=</span><span style="color:#ae81ff">10</span>
</span></span><span style="display:flex;"><span>20/05/08 13:59:24 INFO mapred.JobClient:     SPLIT_RAW_BYTES<span style="color:#f92672">=</span><span style="color:#ae81ff">245</span>
</span></span><span style="display:flex;"><span>20/05/08 13:59:24 INFO mapred.JobClient:     Map output bytes<span style="color:#f92672">=</span><span style="color:#ae81ff">215</span>
</span></span><span style="display:flex;"><span>20/05/08 13:59:24 INFO mapred.JobClient:     Reduce shuffle bytes<span style="color:#f92672">=</span><span style="color:#ae81ff">267</span>
</span></span><span style="display:flex;"><span>20/05/08 13:59:24 INFO mapred.JobClient:     Reduce input groups<span style="color:#f92672">=</span><span style="color:#ae81ff">10</span>
</span></span><span style="display:flex;"><span>20/05/08 13:59:24 INFO mapred.JobClient:     Combine output records<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>20/05/08 13:59:24 INFO mapred.JobClient:     Reduce output records<span style="color:#f92672">=</span><span style="color:#ae81ff">10</span>
</span></span><span style="display:flex;"><span>20/05/08 13:59:24 INFO mapred.JobClient:     Map output records<span style="color:#f92672">=</span><span style="color:#ae81ff">20</span>
</span></span><span style="display:flex;"><span>20/05/08 13:59:24 INFO mapred.JobClient:     Combine input records<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>20/05/08 13:59:24 INFO mapred.JobClient:     Total committed heap usage <span style="color:#f92672">(</span>bytes<span style="color:#f92672">)=</span><span style="color:#ae81ff">578813952</span>
</span></span><span style="display:flex;"><span>20/05/08 13:59:24 INFO mapred.JobClient:   File Input Format Counters 
</span></span><span style="display:flex;"><span>20/05/08 13:59:24 INFO mapred.JobClient:     Bytes Read<span style="color:#f92672">=</span><span style="color:#ae81ff">135</span>
</span></span><span style="display:flex;"><span>20/05/08 13:59:24 INFO mapred.JobClient:   FileSystemCounters
</span></span><span style="display:flex;"><span>20/05/08 13:59:24 INFO mapred.JobClient:     HDFS_BYTES_READ<span style="color:#f92672">=</span><span style="color:#ae81ff">380</span>
</span></span><span style="display:flex;"><span>20/05/08 13:59:24 INFO mapred.JobClient:     FILE_BYTES_WRITTEN<span style="color:#f92672">=</span><span style="color:#ae81ff">156788</span>
</span></span><span style="display:flex;"><span>20/05/08 13:59:24 INFO mapred.JobClient:     FILE_BYTES_READ<span style="color:#f92672">=</span><span style="color:#ae81ff">261</span>
</span></span><span style="display:flex;"><span>20/05/08 13:59:24 INFO mapred.JobClient:     HDFS_BYTES_WRITTEN<span style="color:#f92672">=</span><span style="color:#ae81ff">91</span>
</span></span><span style="display:flex;"><span>20/05/08 13:59:24 INFO mapred.JobClient:   Job Counters 
</span></span><span style="display:flex;"><span>20/05/08 13:59:24 INFO mapred.JobClient:     Launched map tasks<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>
</span></span><span style="display:flex;"><span>20/05/08 13:59:24 INFO mapred.JobClient:     Launched reduce tasks<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>20/05/08 13:59:24 INFO mapred.JobClient:     SLOTS_MILLIS_REDUCES<span style="color:#f92672">=</span><span style="color:#ae81ff">8065</span>
</span></span><span style="display:flex;"><span>20/05/08 13:59:24 INFO mapred.JobClient:     Total time spent by all reduces waiting after reserving slots <span style="color:#f92672">(</span>ms<span style="color:#f92672">)=</span><span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>20/05/08 13:59:24 INFO mapred.JobClient:     SLOTS_MILLIS_MAPS<span style="color:#f92672">=</span><span style="color:#ae81ff">4142</span>
</span></span><span style="display:flex;"><span>20/05/08 13:59:24 INFO mapred.JobClient:     Total time spent by all maps waiting after reserving slots <span style="color:#f92672">(</span>ms<span style="color:#f92672">)=</span><span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>20/05/08 13:59:24 INFO mapred.JobClient:     Data-local map tasks<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>
</span></span><span style="display:flex;"><span>20/05/08 13:59:24 INFO mapred.JobClient:   File Output Format Counters 
</span></span><span style="display:flex;"><span>20/05/08 13:59:24 INFO mapred.JobClient:     Bytes Written<span style="color:#f92672">=</span><span style="color:#ae81ff">91</span>
</span></span></code></pre></div><h3 id="查看执行结果">查看执行结果<a hidden class="anchor" aria-hidden="true" href="#查看执行结果">#</a></h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>MacBook-Pro-of-Wxk:Project root# hadoop fs -ls output_wordcount
</span></span><span style="display:flex;"><span>Found <span style="color:#ae81ff">3</span> items
</span></span><span style="display:flex;"><span>-rw-r--r--   <span style="color:#ae81ff">3</span> root supergroup          <span style="color:#ae81ff">0</span> 2020-05-08 13:59 /user/root/output_wordcount/_SUCCESS
</span></span><span style="display:flex;"><span>drwxr-xr-x   - root supergroup          <span style="color:#ae81ff">0</span> 2020-05-08 13:59 /user/root/output_wordcount/_logs
</span></span><span style="display:flex;"><span>-rw-r--r--   <span style="color:#ae81ff">3</span> root supergroup         <span style="color:#ae81ff">91</span> 2020-05-08 13:59 /user/root/output_wordcount/part-r-00000
</span></span></code></pre></div><p>其中，part-r-00000 就包含执行的结果，即统计了两个文件中，每个单词的总个数，并且按照字典顺序排序：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>MacBook-Pro-of-Wxk:Project root# hadoop fs -cat output_wordcount/part-r-00000
</span></span><span style="display:flex;"><span>BigData	<span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>DataNode	<span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>HDFS	<span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>Hadoop	<span style="color:#ae81ff">5</span>
</span></span><span style="display:flex;"><span>Hello	<span style="color:#ae81ff">6</span>
</span></span><span style="display:flex;"><span>Map	<span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>MapReduce	<span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>NameNode	<span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>Reduce	<span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>World	<span style="color:#ae81ff">2</span>
</span></span></code></pre></div><h2 id="利用-mapreduce-进行排序">利用 MapReduce 进行排序<a hidden class="anchor" aria-hidden="true" href="#利用-mapreduce-进行排序">#</a></h2>
<p>将多个文件中的数字排序。</p>
<h3 id="mapreduce-过程-1">MapReduce 过程<a hidden class="anchor" aria-hidden="true" href="#mapreduce-过程-1">#</a></h3>
<ul>
<li>Map：将数据分片后，将数字按照区间进行标记。</li>
<li>Reduce：将每个分区的数字分别进行排序，最后合并。</li>
</ul>
<p><img alt="Reduce过程" loading="lazy" src="/posts/%E5%A4%A7%E6%95%B0%E6%8D%AE/hadoop/hadoop%E5%9F%BA%E7%A1%80%E7%AF%87/images/image-20200508141137261.png"></p>
<h3 id="源码-1">源码<a hidden class="anchor" aria-hidden="true" href="#源码-1">#</a></h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-java" data-lang="java"><span style="display:flex;"><span><span style="color:#f92672">import</span> java.io.IOException;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> java.util.StringTokenizer;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> org.apache.hadoop.conf.Configuration;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> org.apache.hadoop.fs.Path;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> org.apache.hadoop.io.IntWritable;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> org.apache.hadoop.io.Text;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> org.apache.hadoop.mapreduce.Job;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> org.apache.hadoop.mapreduce.Mapper;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> org.apache.hadoop.mapreduce.Reducer;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> org.apache.hadoop.mapreduce.Partitioner;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> org.apache.hadoop.util.GenericOptionsParser;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">public</span> <span style="color:#66d9ef">class</span> <span style="color:#a6e22e">Sort</span> {
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">public</span> <span style="color:#66d9ef">static</span> <span style="color:#66d9ef">class</span> <span style="color:#a6e22e">Map</span> <span style="color:#66d9ef">extends</span>
</span></span><span style="display:flex;"><span>			Mapper<span style="color:#f92672">&lt;</span>Object, Text, IntWritable, IntWritable<span style="color:#f92672">&gt;</span> {
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>		<span style="color:#66d9ef">private</span> <span style="color:#66d9ef">static</span> IntWritable data <span style="color:#f92672">=</span> <span style="color:#66d9ef">new</span> IntWritable();
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>		<span style="color:#66d9ef">public</span> <span style="color:#66d9ef">void</span> <span style="color:#a6e22e">map</span>(Object key, Text value, Context context)
</span></span><span style="display:flex;"><span>				<span style="color:#66d9ef">throws</span> IOException, InterruptedException {
</span></span><span style="display:flex;"><span>			String line <span style="color:#f92672">=</span> value.<span style="color:#a6e22e">toString</span>();
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>			data.<span style="color:#a6e22e">set</span>(Integer.<span style="color:#a6e22e">parseInt</span>(line));
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>			context.<span style="color:#a6e22e">write</span>(data, <span style="color:#66d9ef">new</span> IntWritable(1));
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>		}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">public</span> <span style="color:#66d9ef">static</span> <span style="color:#66d9ef">class</span> <span style="color:#a6e22e">Reduce</span> <span style="color:#66d9ef">extends</span>
</span></span><span style="display:flex;"><span>			Reducer<span style="color:#f92672">&lt;</span>IntWritable, IntWritable, IntWritable, IntWritable<span style="color:#f92672">&gt;</span> {
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>		<span style="color:#66d9ef">private</span> <span style="color:#66d9ef">static</span> IntWritable linenum <span style="color:#f92672">=</span> <span style="color:#66d9ef">new</span> IntWritable(1);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>		<span style="color:#66d9ef">public</span> <span style="color:#66d9ef">void</span> <span style="color:#a6e22e">reduce</span>(IntWritable key, Iterable<span style="color:#f92672">&lt;</span>IntWritable<span style="color:#f92672">&gt;</span> values,
</span></span><span style="display:flex;"><span>				Context context) <span style="color:#66d9ef">throws</span> IOException, InterruptedException {
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>			<span style="color:#66d9ef">for</span> (IntWritable val : values) {
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>				context.<span style="color:#a6e22e">write</span>(linenum, key);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>				linenum <span style="color:#f92672">=</span> <span style="color:#66d9ef">new</span> IntWritable(linenum.<span style="color:#a6e22e">get</span>() <span style="color:#f92672">+</span> 1);
</span></span><span style="display:flex;"><span>			}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>		}
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">public</span> <span style="color:#66d9ef">static</span> <span style="color:#66d9ef">class</span> <span style="color:#a6e22e">Partition</span> <span style="color:#66d9ef">extends</span> Partitioner<span style="color:#f92672">&lt;</span>IntWritable, IntWritable<span style="color:#f92672">&gt;</span> {
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">@Override</span>
</span></span><span style="display:flex;"><span>		<span style="color:#66d9ef">public</span> <span style="color:#66d9ef">int</span> <span style="color:#a6e22e">getPartition</span>(IntWritable key, IntWritable value,
</span></span><span style="display:flex;"><span>				<span style="color:#66d9ef">int</span> numPartitions) {
</span></span><span style="display:flex;"><span>			<span style="color:#66d9ef">int</span> MaxNumber <span style="color:#f92672">=</span> 65223;
</span></span><span style="display:flex;"><span>			<span style="color:#66d9ef">int</span> bound <span style="color:#f92672">=</span> MaxNumber <span style="color:#f92672">/</span> numPartitions <span style="color:#f92672">+</span> 1;
</span></span><span style="display:flex;"><span>			<span style="color:#66d9ef">int</span> keynumber <span style="color:#f92672">=</span> key.<span style="color:#a6e22e">get</span>();
</span></span><span style="display:flex;"><span>			<span style="color:#66d9ef">for</span> (<span style="color:#66d9ef">int</span> i <span style="color:#f92672">=</span> 0; i <span style="color:#f92672">&lt;</span> numPartitions; i<span style="color:#f92672">++</span>) {
</span></span><span style="display:flex;"><span>				<span style="color:#66d9ef">if</span> (keynumber <span style="color:#f92672">&lt;</span> bound <span style="color:#f92672">*</span> i <span style="color:#f92672">&amp;&amp;</span> keynumber <span style="color:#f92672">&gt;=</span> bound <span style="color:#f92672">*</span> (i <span style="color:#f92672">-</span> 1))
</span></span><span style="display:flex;"><span>					<span style="color:#66d9ef">return</span> i <span style="color:#f92672">-</span> 1;
</span></span><span style="display:flex;"><span>			}
</span></span><span style="display:flex;"><span>			<span style="color:#66d9ef">return</span> 0;
</span></span><span style="display:flex;"><span>		}
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>	<span style="color:#75715e">/**
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">	 * @param args
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">	 */</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">public</span> <span style="color:#66d9ef">static</span> <span style="color:#66d9ef">void</span> <span style="color:#a6e22e">main</span>(String<span style="color:#f92672">[]</span> args) <span style="color:#66d9ef">throws</span> Exception {
</span></span><span style="display:flex;"><span>		<span style="color:#75715e">// TODO Auto-generated method stub</span>
</span></span><span style="display:flex;"><span>		Configuration conf <span style="color:#f92672">=</span> <span style="color:#66d9ef">new</span> Configuration();
</span></span><span style="display:flex;"><span>		String<span style="color:#f92672">[]</span> otherArgs <span style="color:#f92672">=</span> <span style="color:#66d9ef">new</span> GenericOptionsParser(conf, args)
</span></span><span style="display:flex;"><span>				.<span style="color:#a6e22e">getRemainingArgs</span>();
</span></span><span style="display:flex;"><span>		<span style="color:#66d9ef">if</span> (otherArgs.<span style="color:#a6e22e">length</span> <span style="color:#f92672">!=</span> 2) {
</span></span><span style="display:flex;"><span>			System.<span style="color:#a6e22e">err</span>.<span style="color:#a6e22e">println</span>(<span style="color:#e6db74">&#34;Usage Sort &lt;int&gt; &lt;out&gt;&#34;</span>);
</span></span><span style="display:flex;"><span>			System.<span style="color:#a6e22e">exit</span>(2);
</span></span><span style="display:flex;"><span>		}
</span></span><span style="display:flex;"><span>		Job job <span style="color:#f92672">=</span> <span style="color:#66d9ef">new</span> Job(conf, <span style="color:#e6db74">&#34;Sort&#34;</span>);
</span></span><span style="display:flex;"><span>		job.<span style="color:#a6e22e">setJarByClass</span>(Sort.<span style="color:#a6e22e">class</span>);
</span></span><span style="display:flex;"><span>		job.<span style="color:#a6e22e">setMapperClass</span>(Map.<span style="color:#a6e22e">class</span>);
</span></span><span style="display:flex;"><span>		job.<span style="color:#a6e22e">setPartitionerClass</span>(Partition.<span style="color:#a6e22e">class</span>);
</span></span><span style="display:flex;"><span>		job.<span style="color:#a6e22e">setReducerClass</span>(Reduce.<span style="color:#a6e22e">class</span>);
</span></span><span style="display:flex;"><span>		job.<span style="color:#a6e22e">setOutputKeyClass</span>(IntWritable.<span style="color:#a6e22e">class</span>);
</span></span><span style="display:flex;"><span>		job.<span style="color:#a6e22e">setOutputValueClass</span>(IntWritable.<span style="color:#a6e22e">class</span>);
</span></span><span style="display:flex;"><span>		FileInputFormat.<span style="color:#a6e22e">addInputPath</span>(job, <span style="color:#66d9ef">new</span> Path(otherArgs<span style="color:#f92672">[</span>0<span style="color:#f92672">]</span>));
</span></span><span style="display:flex;"><span>		FileOutputFormat.<span style="color:#a6e22e">setOutputPath</span>(job, <span style="color:#66d9ef">new</span> Path(otherArgs<span style="color:#f92672">[</span>1<span style="color:#f92672">]</span>));
</span></span><span style="display:flex;"><span>		System.<span style="color:#a6e22e">exit</span>(job.<span style="color:#a6e22e">waitForCompletion</span>(<span style="color:#66d9ef">true</span>) <span style="color:#f92672">?</span> 0 : 1);
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><h3 id="编译和打包-1">编译和打包<a hidden class="anchor" aria-hidden="true" href="#编译和打包-1">#</a></h3>
<p>编译：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>javac -classpath /Library/hadoop-1.2.1/hadoop-core-1.2.1.jar:/Library/hadoop-1.2.1/lib/commons-cli-1.2.jar -d SortClass/ Sort.java
</span></span></code></pre></div><p>打包：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>jar -cvf Sort.jar *.class
</span></span></code></pre></div><h3 id="准备文件-1">准备文件<a hidden class="anchor" aria-hidden="true" href="#准备文件-1">#</a></h3>
<p>Numbers.txt</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-txt" data-lang="txt"><span style="display:flex;"><span>199
</span></span><span style="display:flex;"><span>3
</span></span><span style="display:flex;"><span>609
</span></span><span style="display:flex;"><span>456
</span></span><span style="display:flex;"><span>789
</span></span><span style="display:flex;"><span>119
</span></span></code></pre></div><p>Numbers2.txt</p>
<pre tabindex="0"><code>478
971
988
125
9
3
1
</code></pre><h3 id="上传文件-2">上传文件<a hidden class="anchor" aria-hidden="true" href="#上传文件-2">#</a></h3>
<p>在 HDFS 中创建 input_sort 文件夹：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>hadoop fs -mkdir input_sort
</span></span></code></pre></div><p>将两个文本文件上传到 HDFS：</p>
<pre tabindex="0"><code>hadoop fs -put Sort/* input_sort/
</code></pre><h3 id="执行-mapreduce-1">执行 MapReduce<a hidden class="anchor" aria-hidden="true" href="#执行-mapreduce-1">#</a></h3>
<pre tabindex="0"><code>hadoop jar Hadoop/WordCount/WordCountClass/WordCount.jar WordCount input_wordcount output_wordcount
</code></pre><p>执行过程和结果：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>MacBook-Pro-of-Wxk:Project root# hadoop jar Hadoop/Sort/SortClass/Sort.jar Sort input_sort output_sort
</span></span><span style="display:flex;"><span>20/05/08 14:58:36 INFO input.FileInputFormat: Total input paths to process : <span style="color:#ae81ff">2</span>
</span></span><span style="display:flex;"><span>20/05/08 14:58:36 WARN util.NativeCodeLoader: Unable to load native-hadoop library <span style="color:#66d9ef">for</span> your platform... using builtin-java classes where applicable
</span></span><span style="display:flex;"><span>20/05/08 14:58:36 WARN snappy.LoadSnappy: Snappy native library not loaded
</span></span><span style="display:flex;"><span>20/05/08 14:58:36 INFO mapred.JobClient: Running job: job_202005081303_0002
</span></span><span style="display:flex;"><span>20/05/08 14:58:37 INFO mapred.JobClient:  map 0% reduce 0%
</span></span><span style="display:flex;"><span>20/05/08 14:58:40 INFO mapred.JobClient:  map 100% reduce 0%
</span></span><span style="display:flex;"><span>20/05/08 14:58:48 INFO mapred.JobClient:  map 100% reduce 100%
</span></span><span style="display:flex;"><span>20/05/08 14:58:48 INFO mapred.JobClient: Job complete: job_202005081303_0002
</span></span><span style="display:flex;"><span>20/05/08 14:58:48 INFO mapred.JobClient: Counters: <span style="color:#ae81ff">26</span>
</span></span><span style="display:flex;"><span>20/05/08 14:58:48 INFO mapred.JobClient:   Map-Reduce Framework
</span></span><span style="display:flex;"><span>20/05/08 14:58:48 INFO mapred.JobClient:     Spilled Records<span style="color:#f92672">=</span><span style="color:#ae81ff">26</span>
</span></span><span style="display:flex;"><span>20/05/08 14:58:48 INFO mapred.JobClient:     Map output materialized bytes<span style="color:#f92672">=</span><span style="color:#ae81ff">142</span>
</span></span><span style="display:flex;"><span>20/05/08 14:58:48 INFO mapred.JobClient:     Reduce input records<span style="color:#f92672">=</span><span style="color:#ae81ff">13</span>
</span></span><span style="display:flex;"><span>20/05/08 14:58:48 INFO mapred.JobClient:     Map input records<span style="color:#f92672">=</span><span style="color:#ae81ff">13</span>
</span></span><span style="display:flex;"><span>20/05/08 14:58:48 INFO mapred.JobClient:     SPLIT_RAW_BYTES<span style="color:#f92672">=</span><span style="color:#ae81ff">239</span>
</span></span><span style="display:flex;"><span>20/05/08 14:58:48 INFO mapred.JobClient:     Map output bytes<span style="color:#f92672">=</span><span style="color:#ae81ff">104</span>
</span></span><span style="display:flex;"><span>20/05/08 14:58:48 INFO mapred.JobClient:     Reduce shuffle bytes<span style="color:#f92672">=</span><span style="color:#ae81ff">142</span>
</span></span><span style="display:flex;"><span>20/05/08 14:58:48 INFO mapred.JobClient:     Reduce input groups<span style="color:#f92672">=</span><span style="color:#ae81ff">12</span>
</span></span><span style="display:flex;"><span>20/05/08 14:58:48 INFO mapred.JobClient:     Combine output records<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>20/05/08 14:58:48 INFO mapred.JobClient:     Reduce output records<span style="color:#f92672">=</span><span style="color:#ae81ff">13</span>
</span></span><span style="display:flex;"><span>20/05/08 14:58:48 INFO mapred.JobClient:     Map output records<span style="color:#f92672">=</span><span style="color:#ae81ff">13</span>
</span></span><span style="display:flex;"><span>20/05/08 14:58:48 INFO mapred.JobClient:     Combine input records<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>20/05/08 14:58:48 INFO mapred.JobClient:     Total committed heap usage <span style="color:#f92672">(</span>bytes<span style="color:#f92672">)=</span><span style="color:#ae81ff">578813952</span>
</span></span><span style="display:flex;"><span>20/05/08 14:58:48 INFO mapred.JobClient:   File Input Format Counters 
</span></span><span style="display:flex;"><span>20/05/08 14:58:48 INFO mapred.JobClient:     Bytes Read<span style="color:#f92672">=</span><span style="color:#ae81ff">44</span>
</span></span><span style="display:flex;"><span>20/05/08 14:58:48 INFO mapred.JobClient:   FileSystemCounters
</span></span><span style="display:flex;"><span>20/05/08 14:58:48 INFO mapred.JobClient:     HDFS_BYTES_READ<span style="color:#f92672">=</span><span style="color:#ae81ff">283</span>
</span></span><span style="display:flex;"><span>20/05/08 14:58:48 INFO mapred.JobClient:     FILE_BYTES_WRITTEN<span style="color:#f92672">=</span><span style="color:#ae81ff">156172</span>
</span></span><span style="display:flex;"><span>20/05/08 14:58:48 INFO mapred.JobClient:     FILE_BYTES_READ<span style="color:#f92672">=</span><span style="color:#ae81ff">136</span>
</span></span><span style="display:flex;"><span>20/05/08 14:58:48 INFO mapred.JobClient:     HDFS_BYTES_WRITTEN<span style="color:#f92672">=</span><span style="color:#ae81ff">74</span>
</span></span><span style="display:flex;"><span>20/05/08 14:58:48 INFO mapred.JobClient:   Job Counters 
</span></span><span style="display:flex;"><span>20/05/08 14:58:48 INFO mapred.JobClient:     Launched map tasks<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>
</span></span><span style="display:flex;"><span>20/05/08 14:58:48 INFO mapred.JobClient:     Launched reduce tasks<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>20/05/08 14:58:48 INFO mapred.JobClient:     SLOTS_MILLIS_REDUCES<span style="color:#f92672">=</span><span style="color:#ae81ff">7980</span>
</span></span><span style="display:flex;"><span>20/05/08 14:58:48 INFO mapred.JobClient:     Total time spent by all reduces waiting after reserving slots <span style="color:#f92672">(</span>ms<span style="color:#f92672">)=</span><span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>20/05/08 14:58:48 INFO mapred.JobClient:     SLOTS_MILLIS_MAPS<span style="color:#f92672">=</span><span style="color:#ae81ff">3902</span>
</span></span><span style="display:flex;"><span>20/05/08 14:58:48 INFO mapred.JobClient:     Total time spent by all maps waiting after reserving slots <span style="color:#f92672">(</span>ms<span style="color:#f92672">)=</span><span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>20/05/08 14:58:48 INFO mapred.JobClient:     Data-local map tasks<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>
</span></span><span style="display:flex;"><span>20/05/08 14:58:48 INFO mapred.JobClient:   File Output Format Counters 
</span></span><span style="display:flex;"><span>20/05/08 14:58:48 INFO mapred.JobClient:     Bytes Written<span style="color:#f92672">=</span><span style="color:#ae81ff">74</span>
</span></span></code></pre></div><h3 id="查看执行结果-1">查看执行结果<a hidden class="anchor" aria-hidden="true" href="#查看执行结果-1">#</a></h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>MacBook-Pro-of-Wxk:Project root# hadoop fs -ls output_sort
</span></span><span style="display:flex;"><span>Found <span style="color:#ae81ff">3</span> items
</span></span><span style="display:flex;"><span>-rw-r--r--   <span style="color:#ae81ff">3</span> root supergroup          <span style="color:#ae81ff">0</span> 2020-05-08 14:58 /user/root/output_sort/_SUCCESS
</span></span><span style="display:flex;"><span>drwxr-xr-x   - root supergroup          <span style="color:#ae81ff">0</span> 2020-05-08 14:58 /user/root/output_sort/_logs
</span></span><span style="display:flex;"><span>-rw-r--r--   <span style="color:#ae81ff">3</span> root supergroup         <span style="color:#ae81ff">74</span> 2020-05-08 14:58 /user/root/output_sort/part-r-00000
</span></span></code></pre></div><p>其中，part-r-00000 就包含执行的结果，即两个文件中所有数字从小到大排序后的排名和数字。</p>
<pre tabindex="0"><code>MacBook-Pro-of-Wxk:Project root# hadoop fs -cat output_sort/part-r-00000
1	1
2	3
3	3
4	9
5	119
6	125
7	199
8	456
9	478
10	609
11	789
12	971
13	988
</code></pre>

  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="http://localhost:1313/tags/hadoop/">Hadoop</a></li>
      <li><a href="http://localhost:1313/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/">大数据</a></li>
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2024 <a href="http://localhost:1313/">Xinkang&#39;s Blog</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
